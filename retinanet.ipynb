{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0294b6-3a14-4c52-9182-814c300bf0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from torch import Tensor\n",
    "from collections import OrderedDict\n",
    "from torchvision.models.detection.rpn import concat_box_prediction_layers\n",
    "import torchvision\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "FILE_PATH = 'labels/BBox_List_2017.csv'\n",
    "BASE_DIR = 'xray_data'\n",
    "EXCLUDED_LABELS = ['Nodule', 'Pneumothorax', 'Mass','Pneumonia', 'Infiltrate']\n",
    "\n",
    "def load_and_filter_data(file_path, exclude_labels):\n",
    "    data = pd.read_csv(file_path)\n",
    "    for label in exclude_labels:\n",
    "        data = data[~data['Finding Label'].str.contains(label, na=False)]\n",
    "    df_labels = data[['Image Index', 'Finding Label', 'Bbox [x', 'y', 'w', 'h]']]\n",
    "    df_labels.columns = ['Image Index', 'Finding Label', 'Bbox_x', 'Bbox_y', 'Bbox_w', 'Bbox_h']\n",
    "    return df_labels\n",
    "\n",
    "def find_image_path_nested(image_index, base_dir):\n",
    "    \n",
    "    for subfolder in sorted(os.listdir(base_dir)):  \n",
    "        nested_images_path = os.path.join(base_dir, subfolder, 'images')\n",
    "        if os.path.exists(nested_images_path) and os.path.isdir(nested_images_path):\n",
    "            image_path = os.path.join(nested_images_path, image_index)\n",
    "            if os.path.exists(image_path):\n",
    "                return image_path\n",
    "    return None\n",
    "    \n",
    "def preprocess_data(df_labels: pd.DataFrame, base_dir: str) -> pd.DataFrame:\n",
    "    \n",
    "    df_labels['Image Path'] = df_labels['Image Index'].apply(lambda x: find_image_path_nested(x, base_dir))\n",
    "    df_labels = df_labels.dropna(subset=['Image Path'])\n",
    "    df_labels['Bbox_xmax'] = df_labels['Bbox_x'] + df_labels['Bbox_w']\n",
    "    df_labels['Bbox_ymax'] = df_labels['Bbox_y'] + df_labels['Bbox_h']\n",
    "    return df_labels[['Image Path', 'Finding Label', 'Bbox_x', 'Bbox_y', 'Bbox_xmax', 'Bbox_ymax']]\n",
    "\n",
    "df_labels = load_and_filter_data(FILE_PATH, EXCLUDED_LABELS)\n",
    "    \n",
    "df_labels = preprocess_data(df_labels, BASE_DIR)\n",
    "\n",
    "class_counts = df_labels['Finding Label'].value_counts()\n",
    "    \n",
    "imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "print(\"Imbalance Ratio:\", imbalance_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8412e-d805-4d7d-8aba-6be7e03a7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df_labels['Finding Label'].value_counts()\n",
    "fig, ax1 = plt.subplots(1, 1,figsize = (12, 8))\n",
    "ax1.bar(np.arange(len(label_counts)) + 0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts)) + 0.5)\n",
    "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e5971-643f-4797-852e-e199cb0d8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_labels['Bbox_width'] = df_labels['Bbox_xmax'] - df_labels['Bbox_x']\n",
    "df_labels['Bbox_height'] = df_labels['Bbox_ymax'] - df_labels['Bbox_y']\n",
    "\n",
    "\n",
    "df_labels['Bbox_area'] = df_labels['Bbox_width'] * df_labels['Bbox_height']\n",
    "\n",
    "\n",
    "average_bbox_size_per_class = df_labels.groupby('Finding Label')['Bbox_area'].mean()\n",
    "\n",
    "print(\"Average Bounding Box Size (Area) per Class:\")\n",
    "print(average_bbox_size_per_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6853a8ac-a123-401e-8820-f84e23740c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_idx = {label: idx for idx, label in enumerate(df_labels['Finding Label'].unique())}\n",
    "print(label_to_idx)\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "df_shuffled = df_labels.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "n_total = len(df_labels)\n",
    "n_train = int(n_total * train_ratio)\n",
    "n_val = int(n_total * val_ratio)\n",
    "\n",
    "\n",
    "train_data = df_shuffled[:n_train]\n",
    "val_data = df_shuffled[n_train:n_train + n_val]\n",
    "test_data = df_shuffled[n_train + n_val:]\n",
    "\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "\n",
    "class_counts_train = train_data['Finding Label'].value_counts()\n",
    "print(class_counts_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8878941-e74f-4d6f-944b-284af168eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "\n",
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, label_to_idx,dataframe, transforms=None):\n",
    "        \n",
    "        self.dataframe = dataframe\n",
    "        self.transforms = transforms\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        row = self.dataframe.iloc[idx]\n",
    "    \n",
    "        img_path = row['Image Path']\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "      \n",
    "        boxes = torch.tensor([[row['Bbox_x'], row['Bbox_y'], row['Bbox_xmax'], row['Bbox_ymax']]], dtype=torch.float32)\n",
    "        labels = torch.tensor([label_to_idx[row['Finding Label']]], dtype=torch.int64)\n",
    "\n",
    "        if self.transforms:\n",
    "            if isinstance(self.transforms, RandomRotationAndFlip):\n",
    "                image, boxes = self.transforms(image, boxes)\n",
    "            else:\n",
    "                image = self.transforms(image)\n",
    "\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        \n",
    "        \n",
    "        return image, target\n",
    "\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4800846-d5bf-4d47-b7e5-66e43b4ffeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Note: Augmentation caused decrease in performance\n",
    "\"\"\"train_transforms = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor(),\n",
    "])\"\"\"\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = XRayDataset(label_to_idx,train_data, transforms=val_transforms)\n",
    "val_dataset = XRayDataset(label_to_idx,val_data, transforms=val_transforms)\n",
    "test_dataset = XRayDataset(label_to_idx,test_data, transforms=val_transforms)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 16, shuffle = False, drop_last = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 16)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 24)\n",
    "\n",
    "for images, targets in train_loader:\n",
    "    print(\"Training Image Shape:\", images.shape) \n",
    "    print(\"Bounding Boxes (First Sample):\", targets['boxes'][0])  \n",
    "    print(\"Labels (First Sample):\", targets['labels'][0])  \n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba9b4c5-a3ff-4f18-a7a0-641d10fb78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import RetinaNet_ResNet50_FPN_Weights\n",
    "\n",
    "def initialize_retinanet(num_classes, pretrained_weights=True):\n",
    "   \n",
    "    weights = RetinaNet_ResNet50_FPN_Weights.DEFAULT if pretrained_weights else None\n",
    "    model = torchvision.models.detection.retinanet_resnet50_fpn(weights=weights)\n",
    "\n",
    "    # Classification head\n",
    "    num_anchors = model.head.classification_head.num_anchors\n",
    "    cls_logits = torch.nn.Conv2d(\n",
    "        in_channels=256,\n",
    "        out_channels=num_anchors * num_classes,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        padding=1\n",
    "    )\n",
    "    \n",
    "    prior_probability = 0.01\n",
    "    torch.nn.init.normal_(cls_logits.weight, std=prior_probability) # cls weights\n",
    "    torch.nn.init.constant_(cls_logits.bias, -math.log((1 - prior_probability) / prior_probability)) # cls bias\n",
    "\n",
    "\n",
    "    # Modify cls head \n",
    "    model.head.classification_head.num_classes = num_classes\n",
    "    model.head.classification_head.cls_logits = cls_logits\n",
    "\n",
    "    # Freeze resnet50 backbone parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze detection head: cls and regression\n",
    "    for param in model.head.classification_head.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.head.regression_head.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbdfcb9-4c18-4020-a425-4682d63f74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model,device,train_loader,batch_size):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total_samples = 0 \n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        losses = 0\n",
    "        for j in range(len(images)):\n",
    "\n",
    "            image = images[j].unsqueeze(0).to(device)\n",
    "\n",
    "            boxes = targets[\"boxes\"][j].to(device)\n",
    "            labels = targets[\"labels\"][j].to(device)\n",
    "            target = [{\"boxes\":boxes, \"labels\":labels}]\n",
    "\n",
    "            loss_dictionary = model(image, target)\n",
    "            loss = sum(loss for loss in loss_dictionary.values())\n",
    "            losses += loss\n",
    "            train_loss += loss.item()\n",
    "             \n",
    "        losses /= batch_size\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            print(\"epoch:\", epoch + 1,  \"iteration:\", i + 1,  \"loss:\", loss.item())\n",
    "            \n",
    "    avg_train_loss = train_loss / ((i + 1) * batch_size)\n",
    "\n",
    "    return avg_train_loss\n",
    "\n",
    "def val_one_epoch(model,device,val_loader,batch_size):\n",
    "    model.train()\n",
    "    val_loss = 0\n",
    "    total_samples = 0 \n",
    "    for i, (images, targets) in enumerate(val_loader):\n",
    "        \n",
    "        losses = 0\n",
    "        for j in range(len(images)):\n",
    "\n",
    "            image = images[j].unsqueeze(0).to(device)\n",
    "\n",
    "            boxes = targets[\"boxes\"][j].to(device)\n",
    "            labels = targets[\"labels\"][j].to(device)\n",
    "            target = [{\"boxes\":boxes, \"labels\":labels}]\n",
    "\n",
    "            loss_dictionary = model(image, target)\n",
    "            loss = sum(loss for loss in loss_dictionary.values())\n",
    "            losses += loss\n",
    "            val_loss += loss.item()\n",
    "             \n",
    "        losses /= batch_size\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            print(\"epoch:\", epoch + 1,  \"iteration:\", i + 1,  \"loss:\", loss.item())\n",
    "            \n",
    "    avg_val_loss = val_loss / ((i + 1) * batch_size)\n",
    "\n",
    "    return avg_val_loss\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d200d-82b7-424c-9284-34ce9b83566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(label_to_idx) + 1\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = initialize_retinanet(num_classes)\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr = 0.005, momentum = 0.9, weight_decay = 0.0005)\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "epoch_number = []\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_one_epoch(model,device, train_loader, batch_size)\n",
    "    train_losses.append(train_loss)\n",
    "    print(\"Train loss:\", train_loss)\n",
    " \n",
    "    val_loss = val_one_epoch(model, device,val_loader,batch_size)\n",
    "    val_losses.append(val_loss)\n",
    "    print(\"Val loss: \", val_loss)\n",
    "    epoch_number.append(epoch + 1)\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412b578-4982-455f-8004-f3330eb35d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_number, train_losses, label = \"Training Loss\")\n",
    "plt.plot(epoch_number, val_losses, label = \"Validation Loss\")\n",
    "plt.legend(['Train', 'Validation'], loc = 'upper right')\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig('results_retinanet/loss_retina.png', dpi=300) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ed09c-e8c2-4271-a9ed-da7f0a82ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "model.eval()\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in test_loader:\n",
    "        images = images.cuda()\n",
    "        predictions = model(images)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "    \n",
    "            scores = predictions[i][\"scores\"].cpu().numpy()\n",
    "            if len(scores) > 0: \n",
    "                max_score_idx = scores.argmax()\n",
    "                best_score = scores[max_score_idx]\n",
    "                best_box = predictions[i][\"boxes\"][max_score_idx].cpu().numpy()\n",
    "                best_label_idx = predictions[i][\"labels\"][max_score_idx].item()\n",
    "\n",
    "                best_label = idx_to_label.get(best_label_idx, \"Unknown\")\n",
    "            else:\n",
    "                best_score = None\n",
    "                best_box = None\n",
    "                best_label = None\n",
    "\n",
    "    \n",
    "            true_boxes = targets[\"boxes\"][i].cpu().numpy()\n",
    "            true_labels = [idx_to_label[label.item()] for label in targets[\"labels\"][i]]\n",
    "\n",
    "            results.append({\n",
    "                \"image_index\": i,\n",
    "                \"best_score\": best_score,\n",
    "                \"predicted_box\": best_box,\n",
    "                \"predicted_label\": best_label,\n",
    "                \"true_boxes\": true_boxes,\n",
    "                \"true_labels\": true_labels\n",
    "            })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb6933-7600-403d-a397-32ebc0e810a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for result in results:\n",
    "    print(f\"Image Index: {result['image_index']}\")\n",
    "    print(f\"Best Score: {result['best_score']}\")\n",
    "    print(f\"Predicted Box: {result['predicted_box']}\")\n",
    "    print(f\"Predicted Label: {result['predicted_label']}\")\n",
    "    print(f\"True Boxes: {result['true_boxes']}\")\n",
    "    print(f\"True Labels: {result['true_labels']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7723123-73f6-4c47-9dab-d5c4534de9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    x_min = max(box1[0], box2[0])\n",
    "    y_min = max(box1[1], box2[1])\n",
    "    x_max = min(box1[2], box2[2])\n",
    "    y_max = min(box1[3], box2[3])\n",
    "\n",
    "\n",
    "    intersection = max(0, x_max - x_min) * max(0, y_max - y_min)\n",
    "    area_box1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area_box2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area_box1 + area_box2 - intersection\n",
    "\n",
    "    if union == 0:\n",
    "        return 0\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "\n",
    "true_positives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "iou_theshold = 0.5\n",
    "ious = []\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    true_boxes = result[\"true_boxes\"]\n",
    "    predicted_box = result[\"predicted_box\"]\n",
    "    best_label = result[\"predicted_label\"]\n",
    "    true_labels = result[\"true_labels\"]\n",
    "\n",
    "    if predicted_box is not None:\n",
    "       \n",
    "        iou_scores = [calculate_iou(predicted_box, true_box) for true_box in true_boxes]\n",
    "        max_iou = max(iou_scores) if iou_scores else 0\n",
    "        ious.append(max_iou)\n",
    "\n",
    "        if max_iou > iou_theshold:  \n",
    "            true_positives += 1\n",
    "        else:\n",
    "            false_positives += 1\n",
    "    else:\n",
    "        \n",
    "        false_negatives += len(true_boxes)\n",
    "\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "\n",
    "mean_iou = sum(ious) / len(ious) if ious else 0\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Mean IoU: {mean_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef8e94-2876-4ce8-95de-f98b6da8f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "true_labels_all = []\n",
    "predicted_labels_all = []\n",
    "\n",
    "for result in results:\n",
    "   \n",
    "    true_labels_all.extend([label for label in result[\"true_labels\"]])\n",
    "\n",
    "    \n",
    "    predicted_labels_all.append(result[\"predicted_label\"])\n",
    "\n",
    "true_indices = [label_to_idx[label] for label in true_labels_all if label in label_to_idx]\n",
    "predicted_indices = [label_to_idx[label] for label in predicted_labels_all if label in label_to_idx]\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(true_indices, predicted_indices)\n",
    "\n",
    "\n",
    "labels = list(label_to_idx.keys())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp.plot(ax=ax, cmap=\"Blues\", xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig('results_retinanet/cm_retina.png', dpi=300) \n",
    "plt.show()\n",
    "\n",
    "report = classification_report(true_indices, predicted_indices, target_names=list(label_to_idx.keys()))\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717e5a5-ea76-4911-86c3-bc005fa8a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def plot_results(image, true_boxes, true_labels, predicted_box, predicted_label, predicted_score):\n",
    "    \" Code generate by ChatGPT4\"\n",
    "    \n",
    "    image = image.permute(1, 2, 0).cpu().numpy() \n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "\n",
    "    for i, box in enumerate(true_boxes):\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        width, height = x_max - x_min, y_max - y_min\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min), width, height,\n",
    "            linewidth=2, edgecolor='green', facecolor='none', label=\"True\" if i == 0 else \"\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(\n",
    "            x_min, y_min - 5,\n",
    "            f\"True: {true_labels[i]}\",\n",
    "            color=\"green\",\n",
    "            fontsize=10,\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.5)\n",
    "        )\n",
    "\n",
    "    if predicted_box is not None:\n",
    "        x_min, y_min, x_max, y_max = predicted_box\n",
    "        width, height = x_max - x_min, y_max - y_min\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min), width, height,\n",
    "            linewidth=2, edgecolor='red', facecolor='none', label=\"Predicted\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(\n",
    "            x_min, y_min - 20,\n",
    "            f\"Pred: {predicted_label} ({predicted_score:.2f})\",\n",
    "            color=\"red\",\n",
    "            fontsize=10,\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.5)\n",
    "        )\n",
    "\n",
    "    ax.legend()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "with torch.no_grad():\n",
    "    for images, targets in test_loader:\n",
    "        images = images.cuda()\n",
    "        predictions = model(images)\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "    \n",
    "            scores = predictions[i][\"scores\"].cpu().numpy()\n",
    "            if len(scores) > 0: \n",
    "                max_score_idx = scores.argmax()\n",
    "                best_score = scores[max_score_idx]\n",
    "                best_box = predictions[i][\"boxes\"][max_score_idx].cpu().numpy()\n",
    "                best_label_idx = predictions[i][\"labels\"][max_score_idx].item()\n",
    "\n",
    "                best_label = idx_to_label.get(best_label_idx, \"Unknown\")\n",
    "            else:\n",
    "                best_score = None\n",
    "                best_box = None\n",
    "                best_label = None\n",
    "\n",
    "\n",
    "    \n",
    "            true_boxes = targets[\"boxes\"][i].cpu().numpy()\n",
    "            true_labels = [idx_to_label[label.item()] for label in targets[\"labels\"][i]]\n",
    "            \n",
    "            plot_results(images[i], true_boxes, true_labels, best_box, best_label, best_score)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7cc64d-ae91-4395-829d-5ee96120bf5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
